# End-to-End-RAG-System

<img width="1051" height="509" alt="image" src="https://github.com/user-attachments/assets/d87aeefc-33ef-4c6e-9431-f6c6a860ab34" />
---

## Pipeline Architecture

**Document Loading**  
Supports PDF, TXT, CSV, JSONL formats.

**Embedding Layer**  
Converts all documents into dense vectors using `sentence-transformers/all-MiniLM-L6-v2`.

**Vector Index (FAISS)**  
Builds a cosine-similarity index for fast retrieval.

**Semantic Search**  
Retrieves top-k relevant chunks based on vector similarity.

**Cross-Encoder Reranking**  
Reranks retrieved results using a more precise model: `cross-encoder/ms-marco-MiniLM-L-6-v2`.

**LLM Answer Generation**  
Generates final answers using `microsoft/Phi-3.5-mini-instruct`.

---
## Project Structure
```
rag-engine-core/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Big_Data.pdf              #  corpus / documents
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ semantic_rag_pipeline.ipynb        #  full notebook
â”‚   â””â”€â”€ cleaned_rag_pipeline.ipynb  # clean version fir GitHub 
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ loader.py                 # handle PDFs, CSV, JSONL
â”‚   â”œâ”€â”€ embedder.py               # embedding functions
â”‚   â”œâ”€â”€ retriever.py              # FAISS + reranking
â”‚   â””â”€â”€ generator.py              # LLM answer generation
â”‚
â”œâ”€â”€ requirements.txt              # dependencies
â”‚
â”œâ”€â”€ README.md                     # full project description
```

---

### ğŸ“„ Data Source

For this experiment, the source of our knowledge base was a **PDF lecture on Big Data** from my college course.



### â“ Query

I asked the LLM:

> "What are the characteristics of Big Data?"



### ğŸ¤– Output

The model generated the following response:

<img width="1495" height="265" alt="image" src="https://github.com/user-attachments/assets/eedd994a-fd92-41a6-9acf-70b6045b7e1d" />



### ğŸ“ Notes

- The PDF was processed into small text chunks to serve as a RAG knowledge base.  
- Semantic search was used to retrieve relevant chunks before generating the answer.  
- This demonstrates how a PDF lecture can be converted into an interactive knowledge source for queries.


---

## Install dependencies:

```bash
pip install -r requirements.txt
